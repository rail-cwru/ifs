\chapter{Background and Related Work}
\indent This chapter introduces the context and background for this thesis.
\section{Interpretability}
\indent Machine learning practitioners have a wide palette of methods and tools. With advances in methodologies, practitioners are able to create high performing models for increasingly complex tasks and problems. A variety of models are produced from the diversity of machine learning algorithms and techniques. However, many models with impressively high performances are treated as black boxes - the information and reasons why they arrived at a prediction or decision is not transparent. An example of non-transparency is AlphaGo, a deep learner for playing the game Go, whose decisions for making moves in are unclear. \cite{InterpretDLModels}. The practicality of machine learning systems depends on whether humans can interpret and extract knowledge from the model and trust its predictions \cite{MakeMLInterpretable}. No matter how complexity or high performing the model is, if the system cannot explain its reasoning in a way the human can understand, humans can not act on the system’s decisions.

\indent In machine learning, a system is interpretable if is able to explain in understandable terms to humans. Researchers recognize the importance of interpretability and the amount of research in interpretable machine learning has grown along with surge in deployment of machine learning systems in all domains \citet{RigorousIntretable}. Doshi-Velez and Kim argue that interpretability is needed because problems are fundamentally under-specified. For example, an algorithm’s objective function may be slightly off from the target function and it is computationally or logically unfeasible to enumerate and test all possible inputs to a model. Therefore, the evaluation of an algorithm based on its optimization of the objective function is incomplete. Moreover, the ability to interpret the model is important for debugging, pinpointing the source of error and improve on the current model, and establish trust in the model. 
\section{Feature Selection}
\subsection{Problem Definition}
\indent Classification is the process of categorizing data points into a given set of categories. The category is also known as the target or the class label. The classification task is to approximate a mapping function from the input \(X=[x_1, x_2, ..., x_N]\) to the output class label \(y\) and creates a model that predicts the class label of a data point represented by a set of inputs also known as a feature vector. Features are measurable properties or characteristics that will help predict the target class. An example of a classification problem is predicting whether an email is spam or not spam. The target classes are spam and not spam, and features describing the emails can be word count, frequency of words, location email sent from, etc. 

\indent In supervised learning, we are provided with \(N\) features \(X=[x_1, x_2, ..., x_N]\), the target variable \(y\), and training examples drawn from the probability distribution of \(X\) and \(y\). Features are measurements or observations of properties and characteristics. The size of the feature vector varies from tens to hundreds or even more. The feature selection is the problem of selecting a subset of features in \(X\) to create a mapping to the target output \(y\) that will maximize the objective which is often the prediction performance of the constructed model on future examples.

\subsection{Introduction}
\indent Feature selection is performed before constructing a prediction model for many important reasons. Feature selection can help improve performance by removing irrelevant or noisy features and prevent overfitting to the training examples. Other benefits of feature selection include reduction in computational cost of training models and identification of features relevant or related to the target variable. Also less data is needed to be collected and processed because more training examples are required to create a generalizable model as the number of features increase. Moreover, a smaller feature set creates simpler models that are more easily interpreted by humans and explanatory of the underlying data generation mechanisms.  

\section{Common Feature Selection Strategies}
\indent An exhaustive search of an optimal feature set of size \(k\), \(k < N\) would explore \(N\choose k\) possible feature sets. If the size of the feature set is also optimized, then there is \(2^N\) possible combinations of features. The number of combinations grows exponentially with dimensionality making the search for the optimal feature set a NP-hard problem. Exhaustive search of the feature subspace is costly and impractical. Conventional feature selection strategies are composed of a search algorithm, an objective function to evaluate the feature subset, and a stopping criterion to stop the search. The search algorithm is independent of the evaluation function.

Two techniques for searching through the features subspace are feature ranking and subset search. In the feature ranking methods, features are ranked based on a merit value such as information content, entropy, relevance, etc. and the top \(k\) candidates are selected. The downside is that redundant and irrelevant features are not always removed. In subset search methods, the search process and elementary operations such as addition or removal of a feature to the current features subset are guided by the value of the objective function. The exploration can be computationally expensive with large feature sets and possible combination of features. 

The three main categories for feature selection approaches are filter, wrapper, and embedded. 
\subsection{Filters}
\indent Filters use the feature ranking technique to evaluate individual features or the feature subset based on measures of information, distance, consistency, similarity, and statistical measure \cite{ReviewOfFS}. Evaluation metrics are independent of the performance of the classifier. Filters can be easily used for most classifiers and useful for very high dimensional data because of their fast computation in comparison to the other two methods. However, the selected subset of features does not necessary build the best performing classifier because the evaluation metric may not relate to the performance of the classifier. A popular filter method is a Correlation based Feature Selection algorithm (CFS) proposed by Hall in 1996 \cite{FSAlgo} build on the heuristic that the features highly correlated with the target variable and uncorrelated with each other are good features for the problem. 

\subsection{Wrapper}
\indent Wrapper methods utilized the subset search technique. Since an exhaustive search for the optimal feature set is NP-hard, wrapper methods are suboptimal searches and some greedy method are on computational scale of \(O(N^2)\) \cite{Clopinet}. Forward selection start with an empty set and add features, while backward elimination start with a feature set and subsequently remove features. One example of wrapper method is forward feature selection, a greedy algorithm that starts with an empty feature set and iteratively adds the feature that would most improve an objective function. The classifier’s prediction performance is the common objective function guiding the search to the feature subset that would maximize the classifier’s performance. Wrapper methods can be used with most learning algorithm because the classifier is treated as a black box, but the resulting feature subset is optimal for the specific learning algorithm. A downside of wrapper methods is that the search space grows with the number of features and is computationally expensive because the classifier has to be reevaluated for every new subset of features and becomes unfeasible for large data sets and more computationally expensive learning algorithms. 
\subsection{Embedded and Hybrid}
Embedded methods incorporate or embed feature selection as a part of the learning algorithm. Various variants of decision tree algorithms, such as CART and random forest, are embedded methods. Hybrid methods combine the desired properties of filter and wrapper methods. A filter is first used to reduce the feature space and then a wrapper method is used to find the best feature subset.  

\section{Causal Feature Selection}
\indent Conventional feature selection algorithms in machine learning literature do not uncover causal relationships among features and between feature and target. Although discovering mechanisms not required for finding good predictors, awareness of cause and effect relationships can support in building more transparent model. Moreover by selecting features based on their effectiveness at predicting the target variable, feature selection algorithms may select feature that are the results of experimental side effects rather than a property of the studied system. The causal information provided by the selected features will help interpret the model’s predictions and make them more trustworthy. 

\indent Feature selection can benefit from causal discovery by revealing relevant features and increasing understanding of the data structure. The goal for the causal discovery problem is to discovery the causal relationship between features for a set of \(N\) input features \(X = [x_1, x_2, ..., x_n]\). The target variable is not singled out and any variable can be the target. 

\subsection{Causal Bayesian networks}
\indent Simple models of cause and effect relationship is based on Bayesian networks which aids in the understanding causality. Causal Bayesian networks is framework for representing the causal relationships for a set of random variables \(X = [x_1, x_2, ..., x_n]\) in the structure of a network. A Bayesian network is a directed acyclic graph (DAG) where each node map one to one to a variable in the set of variables \(X\). The Markov condition of Bayesian networks require every node to be conditionally independent of non descendent nodes given its parent node. A causal Bayesian networks is a Bayesian network where directed edges represent the relationship between variables. For all \(x_i\) and \(x_j\) in X, if there is a directed edge from \(x_i\) to \(x_j\), feature \(x_i\) is a direct cause of feature \(x_j\), then A directed path between two nodes indicates a causal relationship. Causal Bayesian network is a map of the dependencies and independencies of X. 

\subsection{d-separation}
Node \(x_i\) is d-separated from \(x_j\) by Z if Z is a set of node that blocks every path between \(x_i\) and \(x_j\). If \(x_i\) and \(x_j\) is not d-separated by C, then they are d-connected. In a causal Bayesian network, two nodes \(x_i\) and \(x_j\) is d-separated by Z if and only if \(x_i\) is conditionally independent of \(x_j\) given Z. \(x_i\) and \(x_j\) are d-connected \(iff\) they are conditionally dependent \cite{Clopinet}. 

\subsection{Markov blanket}
\indent The Markov blanket in a Bayesian network is the set of features that separates a given feature from the rest of the features in the graph. The Markov blanket is composed of direct causes (parents), direct effects (children), and direct causes of direct effects (spouses). Once all the direct causes of the target are known, indirect causes do not provide any additional information since their effect on the target is through a direct cause and captured in the direct cause. Although the children of the target are predictive of the target, knowing all the other causes of the target’s children (spouses) can help explain the amount of effect the target has on the children. The direct causes along with the direct effects of the direct causes enhance each others predictive power. Researchers has suggested that the Markov blanket for the target variable is an important concept for the feature selection problem \cite{MBforCL}. Feature relevant can be be described in relation to the Bayesian network. For any feature \(Y\), a irrelevant feature is disconnected from Y in the network. Features in the Markov blanket of \(Y\), \(MB(Y)\) are strongly relevant features. Features that are not in \(MB(Y)\) but have a directed path to Y are weakly relevant features \cite{Clopinet}. 

\subsection{Causal discovery algorithms}

\indent Learning causal relationships from observation data is a heavily researched area. The two parts of learning a Bayesian network are learning the structure of the graph G and the probability distribution of the variables. Algorithms for discovering the Markov Blanket that attempts to induce the complete causal Bayesian network does not scale with the increase in features. HITON is a more efficient method proposed for discovering Markov blanket \cite{HITON}. HITON first identifies the children and parents of the target. Then then identifies the children of the parent and the parent of the children of the target. Next, a wrapper method is used to search through the possible feature subset and return feature subset that resulted in the best performing classifier. 

\subsection{Greedy Equivalence Search}
The Bayesian network learning problem is to identify a DAG that fits the observed data \(D\) based on an objective function. The Greedy Equivalence Search (GES) algorithm \cite{GES} identifies an optimal structure and can be used to learn a causal network that fits the observed input data. For two DAGs \(H\) and \(G\), \(H\) is an independent map of \(G\) if the independence between variables implied by the structure of \(H\) is also implied by the structure of \(G\). For an independence map H of G, there exist a finite sequence of edge modification that can be applied to G such that after each edge modification H is still an independence map of G and at the end of the sequence G = H. H, G, and the intermediate DAGs G' are a part of the same equivalence class and are said to be equivalent. Meek proposed a two phase greedy algorithm that optimizes a Bayesian scoring function to find the network structure to map the observed data distribution. The algorithm starts with the equivalence class of DAGs that has no dependencies in the structure. In the first phase, edges are greedily added dependencies by considering all single edge addition that can be made to all the DAGs in the current equivalence class. After the algorithm stops at a local maximum, in the second phase, all single edge removals that can be made to all the DAGs in the current equivalence class are considered. The algorithm outputs the local maximum structure at the end of the second phase. Chickering \cite{GES} proved Meek's Conjecture and provided an implementation of GES. Later in the paper, we will be using a causal discovery tool \cite{Pycausal} implemented by the Center of Causal Discovery that performs GES.

\section{Visualization}
\subsection{Visual Analysis}
\indent Machine learning problems often use complex, multivariate data sets that are difficult to explore and gain insights from. When calculating aggregated statistical measures from large data sets, information is lost from oversimplification and misleading information is a common side effect. Visualization is one of the most relevant knowledge extraction method and can help translate raw data into useful information. Visualization of data helps communicates information and enhance people’s understanding of the data. Visual elements such as charts, graphs, maps can people visually and more efficiently identify trends, outliers, and patterns in the data. 

\indent Visual analytic is the combination of visualizations, human factors, and data analysis and the study of analyzing complex data set supported by interactive graphical and visual interfaces.
Although humans are significantly slower than computers, humans have soft knowledge that can not be expressed as inputs to an algorithm. While computers can performance fast calculations with numbers, the inputted data is all they know. For example, for machine learning classification models, the inputs are examples described by a set of features expressed in a table where rows are examples and columns are features. While the algorithm performs and optimizes calculations with the tabular data, the human has knowledge of the mapping from data values to situations in the real world and understand the rich information behind each feature. Furthermore, humans building the models often have a rich knowledge of the problem background and can catch spot mistakes the machines are making or the incorrect conclusions they may arrive at. Humans are also the ones judging whether the model is sensible in the end. Visual analytic is able to combine the computational and processing power of computers with the high visual processing power of humans and their prior knowledge of the problem. By allowing humans to interact with model, incorporate their prior knowledge, and analyze complex model through visual representations, they build a greater understanding of models and increase the trust of its predictions. 

\subsection{Visualization in Machine Learning}
\indent Visual analytic techniques and tools have been proposed and implemented for every step of the machine learning training process to support users in understanding, diagnosing, and improving models. Visualization systems have been created for specific machine learning models such as decision trees and neural networks and for specific domains such as natural language processing. For example, Stef van den Elzen created BaobabView \cite{BaobabView}, an interactive visual system for the construction and analysis of decision trees that incorporates the expert and their prior knowledge, and Yosinski released a software tool to study large deep learning networks through visualizing every neuron in a trained network as it responds to an input image \cite{Yosinski}. Another technique proposed to explain and visualize local explanations, the model’s output for a single example, to establish trust in a model’s predication. Tamagnini implemented Rivelo \cite{Tamagnini}, an explanation interface for interacting and exploring instance level explanation, which is the set of features that explains the prediction of an example. 

\subsection{Performance Analysis}
\indent Other visual systems extract knowledge from the model’s output to allow the users to interact with the visuals of the model’s output to evaluate its performance and explore and understand the model’s predictions. An example of performance analysis systems is ModelTracker \cite{ModelTracker} which lays out examples horizontally from low to high scoring examples to convey overall performance and enables users to directly interact and inspect examples for debugging. Also, Alsallakh created a system for visualizing probabilistic classification data that lays out histograms of prediction scores for each class in a circle to form a confusion wheel \cite{}. 
\indent I had proposed a set of visual methods that can facilitate analysis of the performance of probabilistic classifiers. The methods were integrated into Stacks, an interactive visual analytics system. Prediction scores are shown at the class level using histogram plots. Users can hone in on mistakes by filtering out irrelevant instances. The distribution of prediction scores communicates how confident the classifier is at its prediction. Furthermore, Stacks also incorporated error analysis for assessing why examples may be falsely classified or received a low prediction score.

\subsection{Visualizing for Feature Selection}
\indent Dimensionality reduction is a common strategy for reducing high dimensionality algorithm and to visualize and analyze high dimensional data in one, two, or three dimensional space. For example, t-Distributed Stochastic Neighbor Embedding (t-SNE) is a dimensionality reduction technique and useful for visualizing high dimensional data sets. 

Non-traditional methods of applying dimensional reduction has been implemented and utilizes visualization. Guo in 2003 \cite{Guo} implemented an interactive feature selection approach that uses visuals to identify patterns and feature subspaces from the high dimensional space. Every pair of features is represented in colored matrix where the color codes for the pair wise similarity. The matrix is sorted to highlight interesting clusters in feature subsets, and users can choose a reduced set of features to display the input data. Fernstad and Johansson created an interactive dimensionality reduction system \cite{InteractiveDR}whose process is influenced by the user. The user chooses the metric and parameters that the system uses to select the most import features and then the reduced features are displayed in a parallel coordinate visual or scatterplot matrix. Moreover, INFUSE \cite{INFUSE} is an interactive feature selection system that ranks features by its predictive power calculated across various feature selection algorithms and classifiers and visualizes the ranking in a sorted list. Users can select features to create their own model and compare their custom model to the other established feature sets.

\section{Evaluating Visual Systems}