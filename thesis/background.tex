\chapter{Background and Related Work}
\indent This chapter introduces the context and background for this thesis.
\section{Interpretability}
\indent Machine learning practitioners have a wide palette of methods and tools, and with advances in these methodologies, practitioners are able to create high performing systems for increasingly complex tasks or problems. A variety of models are produced from the diversity of machine learning algorithms and techniques. However, many models with impressively high performances are treated as black boxes - the information and reasons why they arrived at a prediction or decision is not transparent. For example, the reasons why AlphaGo an artificial intelligence system for playing Go, make certain moves in games are unclear. The practicality of machine learning systems does not depend on the complexity or performance of the model but on whether humans can interpret and extract knowledge from the model and trust its predictions. No matter how accurate a system is, if the system can not explain its reasoning in a way the human can understand, the human can not act on the system’s decisions.

\indent In machine learning, a system is interpretable if is able to explain in understandable terms to humans. Researchers recognize the importance of interpretability and the amount of research in interpretable machine learning has grown along with surge in deployment of machine learning systems in all domains \cite{interpretableML}. Interpretability is needed because problems are fundamentally under-specified and incomplete. For example, an algorithm’s objective function may be slightly off from the target function and it is computationally or logically unfeasible to enumerate and test all possible inputs to a model. The ability to interpret the model is also important for debugging, pinpointing the source of error and improve on the current model. Interpretability is also need to establish trust in the model. 
\section{Feature Selection}
\subsection{Classification}
\indent Classification is the process of categorizing data points into a given set of categories. The category is also known as the target or the class label. The classification task is to approximate a mapping function from the input X to the output class label y and creates a model that predicts the class label of a data point represented by a set of inputs also known as a feature vector. Features are measurable properties or characteristics that will help predict the target class. An example of a classification problem is predicting whether an email is spam or not spam. The target classes are spam and not spam, and features describing the emails can be word count, frequency of words, location email sent from, etc. 

\subsection{Introduction}

\indent In supervised learning, we are provided with N features X, the target variable y, and training examples drawn from the probability distribution of X and y. Features are measurements or observations of properties and the size of the feature vector varies from tens to hundreds or even more. The feature selection problem is to select a subset of features in X to create a mapping to the target output Y that will optimizes the prediction performance of the constructed model on future examples. 
\indent Feature selection is performed before constructing a prediction model for many important reasons. Feature selection can help improve classifier performance by removing irrelevant and noisy features and prevent overfitting to the training examples. Other benefits of feature selection include reducing the computational cost of training models, reducing the amount of input data to process and collect, and identifying features that are relevant or related to the target variable. As the number of features increase, more examples are needed to produce a generalizable classifier. Also by reducing the size of the feature set, simpler models that are more easily interpreted by humans and explanatory of the underlying data generation mechanisms are build.  

\section{Common Feature Selection Strategies}
\indent For N features, there exist 2^N possible subset of features. Exhaustive search of the feature subspace is costly and impractical. Conventional feature selection strategies are composed of a search algorithm, an objective function to evaluate the feature subset, and a stopping criterion to stop the search. The search algorithm is independent of the evaluation function.

Two techniques for searching through the features subspace are feature ranking and subset search. In the feature ranking methods, features are ranked based on a merit value such as information content, entropy, relevance, etc. and the top k candidates are selected. The downside of these methods is that redundant and irrelevant features are not always removed. In subset search methods, elementary changes to the current features subset, such as addition or removal of features, are guided by the value of the objective function. This exploratory can be computationally expensive with large feature sets and possible combination of features. 

The three main categories for feature selection approaches are filter, wrapper, and embedded. 
\subsection{Filters}
\indent Filters use the feature ranking technique to evaluate individual features or the feature subset based on measures of information, distance, consistency, similarity, and statistical measure [cite]. Evaluation metrics are independent of the performance of the classifier. Filters can be easily used for most classifiers and useful for very high dimensional data because of their fast computation in comparison to the other two methods. However, the selected subset of features does not necessary build the best performing classifier because the evaluation metric may not relate to the performance of the classifier. 
Filters use the feature ranking technique to evaluate individual features or the feature subset based on measures of information, distance, consistency, similarity, and statistical measure [cite]. Evaluation metrics are independent of the performance of the classifier. Filters can be easily used for most classifiers and useful for very high dimensional data because of their fast computation in comparison to the other two methods. However, the selected subset of features does not necessary build the best performing classifier because the evaluation metric may not relate to the performance of the classifier. 
\subsection{Wrapper}
\indent Wrapper methods utilized the subset search technique. One example of wrapper method is forward feature selection, a greedy algorithm that starts with an empty feature set and iteratively adds the feature that would most improve the classifier’s performance. The prediction performance of the classifier is the objective function guiding the search to the feature subset that would maximize the classifier’s performance. Wrapper methods can be used with most learning algorithm because the classifier is treated as a black box, but the resulting feature subset is optimal for the specific learning algorithm. A downside of wrapper methods is that the search space grows with the number of features and is computationally expensive because the classifier has to be reevaluated for every new subset of features and becomes unfeasible for large data sets and more computationally expensive learning algorithms. 
\subsection{Embedded and Hybrid}
Embedded methods incorporate or embed feature selection as a part of the learning algorithm. Various variants of decision tree algorithms, such as CART and random forest, are embedded methods. Hybrid methods attempt to combine the desired properties of filter and wrapper methods. A filter is first used to reduce the feature space and then a wrapper method is used to find the best feature subset.  

\section{Causal Feature Selection}
\indent Conventional feature selection algorithms in machine learning literature do not uncover causal relationships among features and between feature and target. Although discovering mechanisms not required for finding good predictors, awareness of cause and effect relationships can support in building more transparent model. The causal information provided by the selected features will help interpret the model’s predictions and make them more trustworthy. 

\indent Causal Bayesian networks is framework in which the causal relationships are represented by the structure of the network. A causal Bayesian networks is a directed acyclic graph (DAG). If feature A is a direct cause of feature B, then there is a directed edge from node A to B. A directed path between two features is shown by a directed path between the nodes. 

\subsection{Markov blanket}
\indent The Markov blanket in a Bayesian network is the set of features that separates a given feature from the rest of the features in the graph. The Markov blanket is composed of direct causes (parents), direct effects (children), and direct causes of direct effects (spouses). Once all the direct causes of the target are known, indirect causes do not provide any additional information since their effect on the target is through a direct cause and captured in the direct cause. Although the children of the target are predictive of the target, knowing all the other causes of the target’s children (spouses) can help explain the amount of effect the target has on the children. The direct causes along with the direct effects of the direct causes enhance each others predictive power. 

\section{Visualization}
\subsection{Visual Analysis}
\indent Machine learning problems often use complex, multivariate data sets that are difficult to explore and gain insights from. When calculating aggregated statistical measures from large data sets, information is lost from the oversimplification and misleading information is a common side effect. Visualization is one of the most relevant knowledge extraction method and can help translate raw data into useful information. Visualization of data helps communicates information and enhance people’s understanding of the data. Visual elements such as charts, graphs, maps can people visually and more efficiently identify trends, outliers, and patterns in the data. 

\indent Visual analytic is the combination of visualizations, human factors, and data analysis and the study of analyzing complex data set supported by interactive graphical and visual interfaces.
Although humans are significantly slower than computers, humans have soft knowledge that can not be expressed as inputs to a model. While computers can performance fast calculations with numbers, the inputted data is all they know. For example, for machine learning classification models, the inputs are usually examples described by a set of features expressed in a table where rows are examples and columns are features. While the algorithm performs and optimizes calculations with the tabular data, the human has knowledge of the mapping from data values to situations in the real world and understand the rich information behind each feature. Furthermore, humans building the models often have a rich knowledge of the problem background and can catch spot mistakes the machines are making or the incorrect conclusions they may arrive at. Humans are also the ones judging whether the model is sensible in the end. Visual analytic is able to combine the computational and processing power of computers with the high visual processing power of humans and their prior knowledge of the problem. By allowing humans to interact with model, incorporate their prior knowledge, and analyze complex model through visual representations, they build a greater understanding of models and increase the trust of its predictions. 

\subsection{Visualization in Machine Learning}
\indent Visual analytic techniques and tools have been proposed and implemented for every step of the machine learning training process to support users in understanding, diagnosing, and improving models. Visualization systems have been created for specific machine learning models such as decision trees and neural networks and for specific domains such as natural language processing. 

\indent For example, Stef van den Elzen created BaobabView, an interactive visual system for the construction and analysis of decision trees that incorporates the expert and their prior knowledge 
Yosinski released a software tool to study large deep learning networks through visualizing every neuron in a trained network as it responds to an input image. Another technique proposed to explain and visualize local explanations, the model’s output for a single example, to establish trust in a model’s predication. Tamagnini implemented Rivelo, and explanation interface for interacting and exploring instance level explanation, which is the set of features that explains the prediction of an example. 
Other visual systems extract knowledge from the model’s output to allow the users to interact with the visuals of the model’s output to evaluate, understand, and explore the model’s predictions. For example, ModelTracker 

\subsection{Visualizing for Feature Selection}
\indent Several approaches to incorporating visualization to feature selection have been implemented. Guo represented the pair wise similarity between features in a color coded matrix. The matrix is sorted to highlight interesting clusters in feature subsets and uses can choose a reduced set of features to display the input data. Fernstad and Johansson created an interactive dimensionality reduction system whose process is influenced by the user. The user chooses the metric and parameters that the system uses to select the most import features. Then the reduced features are displayed in a parallel coordinate visual or scatterplot matrix. INFUSE is an interactive feature selection system that ranks features by its predictive power calculated across various feature selection algorithms and classifiers and visualizes the ranking in a sorted list. Users can select features to create their own model and compare their custom model to the other established feature sets. 